// Callback.
function trainingCallback(epochs, RSS, correctness, ETL) {
  system.println("Epochs: " + core.toString(epochs) + ", RSS: " + core.toString(RSS) + ", Correctness: " + core.toString(correctness) + ", ETL: " + core.toString(ETL))
}

// Data to train.
// The training algorithm expects a matrix with a line for each data and a column for each input or output neuron.
dataX = [[0.00],[0.25],[0.50],[0.75],[1.00],[1.25],[1.50],[1.75],[2.00],[2.25],[2.50],[2.75],[3.00],[3.25],[3.50],[3.75],[4.00],[4.25],[4.50],[4.75],[5.00],[5.25],[5.50],[5.75],[6.00],[6.25],[6.50],[6.75],[7.00],[7.25],[7.50],[7.75],[8.00],[8.25],[8.50],[8.75],[9.00],[9.25],[9.50],[9.75],[10.00]]
dataY = [[2.0000],[2.2197],[2.3811],[2.5136],[2.7310],[2.7827],[2.8327],[3.0351],[2.9551],[3.3973],[3.5117],[3.5909],[3.7345],[3.8419],[4.0952],[4.2879],[4.4000],[4.8764],[5.2843],[5.9241],[6.3302],[6.9608],[7.3044],[7.6791],[8.2819],[9.0139],[9.3387],[10.0420],[10.4000],[10.6437],[10.4786],[10.4928],[10.7082],[10.6233],[10.8862],[10.6830],[10.8393],[10.9186],[10.8814],[10.9779],[11.0000]]

nData = core.length(dataX)

// Creates a multilayer Perceptron neural network.
nn = ann.createANN("mlp", 0, 0, 0, 0, 1, 1, 1, 3)
// Displays the untrained neural network.
system.println("ANN before be prepared: " + core.toString(nn))
system.println(core.toString(ann.getLabels(nn)))

// Assigns random starting weights to neural synapses.
nn = ann.prepare(nn, true, true, true)
system.println(core.toString("ANN after be prepared: " + core.toString(nn)))

// Trains the neural network.
statistics = ann.training(nn, dataX, dataY, 0.005, "tanh", "linear", "none", [1, 0], 2000, 0.001, trainingCallback, 100)
// Displays training statistics.
// system.println("Statistics: " + core.toString(statistics))

// Displays the trained neural network.
system.println("Trained ANN: " + core.toString(nn))

// Uses the trained network to estimate the value of the function.

// nn[1,2] = 1.52021
// nn[2,2] = -9.55616
// nn[1,3] = -1.26172
// nn[3,3] = 5.93258
// nn[1,4] = 0.146194
// nn[4,4] = 0.686591
// nn[2,5] = 1.47574
// nn[3,5] = -1.47603
// nn[4,5] = 8.08261
// nn[5,5] = 0.10794

system.println("The output must be f(0.50) = 2.3811")
out = ann.think(nn, [0.50], 1, 1, "tanh", "linear", "none", [1, 0])
system.println("ANN for f(0.50): " + core.toString(nn))
system.println("f(0.50) = " + out[0])

system.println("The output must be f(1.25) = 2.7827")
out = ann.think(nn, [1.25], 1, 1, "tanh", "linear", "none", [1, 0])
system.println("ANN for f(1.25): " + core.toString(nn))
system.println("f(1.25) = " + out[0])

system.println("The output must be f(5.00) = 6.3302")
out = ann.think(nn, [5.00], 1, 1, "tanh", "linear", "none", [1, 0])
system.println("ANN for f(5.00): " + core.toString(nn))
system.println("f(5.00) = " + out[0])

system.println("The output must be f(5.1267) = 6.65671")
out = ann.think(nn, [5.1267], 1, 1, "tanh", "linear", "none", [1, 0])
system.println("ANN for f(5.1267): " + core.toString(nn))
system.println("f(5.1267) = " + out[0])
